{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# from xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background, disc, cup, hemorrhage, exudate\n",
    "class_colors = [(0, 0, 0), (255, 0, 0), (255, 0, 255), (0, 255, 0), (255, 255, 0)]\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    colored_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(5):\n",
    "        colored_mask[mask == i] = class_colors[i]\n",
    "    return colored_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separable Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConvoluton(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(SeparableConvoluton, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size, stride, padding, dilation, groups=in_planes, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_planes, out_planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    # reps(몇 번 반복할지, entry flow에서는 1번(입력2), middle flow에서는 2번(입력3)), grow_firs & is_last(블록마다 확인하여 설정)\n",
    "    def __init__(self, in_planes, out_planes, reps, stride=1, dilation=1, start_with_relu=True, grow_first=True, is_last=True):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        # skip connection\n",
    "        if out_planes != in_planes or stride != 1:\n",
    "            self.skip = nn.Conv2d(in_planes, out_planes, 1, stride=stride, bias=False)\n",
    "            self.skipbn = nn.BatchNorm2d(out_planes)\n",
    "        else:\n",
    "            self.skip = None\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep = []\n",
    "\n",
    "        # entry flow & middel flow\n",
    "        filters = in_planes # 필터 개수를 맞추기 위함\n",
    "        if grow_first: \n",
    "            rep.append(self.relu) \n",
    "            rep.append(SeparableConvoluton(in_planes, out_planes, 3, stride=1, dilation=dilation)) \n",
    "            rep.append(nn.BatchNorm2d(out_planes))\n",
    "            filters = out_planes\n",
    "        \n",
    "        # 반복\n",
    "        for _ in range(reps-1):\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConvoluton(filters, filters, 3, stride=1, dilation=dilation))\n",
    "            rep.append(nn.BatchNorm2d(filters))\n",
    "        \n",
    "        # entry flow에서 사용\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConvoluton(in_planes, out_planes, 3, stride=1, dilation=dilation))\n",
    "            rep.append(nn.BatchNorm2d(out_planes))\n",
    "        \n",
    "        # relu가 시작이 아닐 경우 (entry flow에서 사용)\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "        \n",
    "        if stride != 1: # 각 블록에서 마지막에 stride가 2일 경우\n",
    "            rep.append(SeparableConvoluton(out_planes, out_planes, 3, stride=2))\n",
    "        \n",
    "        if stride == 1 and is_last: # exit flow의 마지막에 사용\n",
    "            rep.append(SeparableConvoluton(out_planes, out_planes, 3, stride=1))\n",
    "\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.rep(input)\n",
    "\n",
    "        # skip connection\n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(input)\n",
    "            skip = self.skipbn(skip)\n",
    "        else:\n",
    "            skip = input\n",
    "        \n",
    "        x += skip\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Aligned Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(nn.Module):\n",
    "    def __init__(self, in_planes=3, os=16):\n",
    "        super(Xception, self).__init__()\n",
    "\n",
    "        if os == 16:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_rate = 1\n",
    "            exit_block_rates = (1, 2)\n",
    "        elif os == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_rate = 2\n",
    "            exit_block_rates = (2, 4)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Entry Flow\n",
    "        self.conv1 = nn.Conv2d(in_planes, 32, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.block1 = Block(64, 128, reps=2, stride=2, start_with_relu=False)\n",
    "        self.block2 = Block(128, 256, reps=2, stride=2, start_with_relu=True, grow_first=True)\n",
    "        self.block3 = Block(256, 728, reps=2, stride=entry_block3_stride, start_with_relu=True, grow_first=True, is_last=True)\n",
    "\n",
    "        # Middle Flow\n",
    "        self.block4  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block5  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block6  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block7  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block8  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block9  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block10 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block11 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block12 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block13 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block14 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block15 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block16 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block17 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block18 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block19 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "\n",
    "        # Exit Flow\n",
    "        self.block20 = Block(728, 1024, reps=2, stride=1, dilation=exit_block_rates[0], start_with_relu=True, grow_first=False, is_last=True)\n",
    "        \n",
    "        self.conv3 = SeparableConvoluton(1024, 1536, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn3 = nn.BatchNorm2d(1536)\n",
    "\n",
    "        self.conv4 = SeparableConvoluton(1536, 1536, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn4 = nn.BatchNorm2d(1536)\n",
    "\n",
    "        self.conv5 = SeparableConvoluton(1536, 2048, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn5 = nn.BatchNorm2d(2048)\n",
    "\n",
    "        # Init weights\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Entry Flow\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        # low_level_features: block1의 결과값으로, deeplabv3+ 구조에서 사용\n",
    "        low_level_features = x\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        \n",
    "        # Middle Flow\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.block9(x)\n",
    "        x = self.block10(x)\n",
    "        x = self.block11(x)\n",
    "        x = self.block12(x)\n",
    "        x = self.block13(x)\n",
    "        x = self.block14(x)\n",
    "        x = self.block15(x)\n",
    "        x = self.block16(x)\n",
    "        x = self.block17(x)\n",
    "        x = self.block18(x)\n",
    "        x = self.block19(x)\n",
    "\n",
    "        # Exit Flow\n",
    "        x = self.block20(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x, low_level_features\n",
    "    \n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            # modules에서 각 레이어가 Conv2d이면 weight를 초기화, BatchNorm2d이면 weight를 1로, bias를 0으로 초기화\n",
    "            if isinstance(m, nn.Conv2d): # isinstance(확인하고자 하는 데이터 값, 확인하고자 하는 데이터 타입), 서로 타입이 같으면 True, 아니면 False\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight) # input tensor가 He초기값으로 N(0,std^2)의 정규분포를 갖는다.\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3plus (seg | reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, rate):\n",
    "        super(ASPP, self).__init__()\n",
    "        if rate == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = rate\n",
    "        \n",
    "        self.atrous_convolution == nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=1, padding=padding, dilation=rate, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.__init_weight()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encodier-decoder & Archictecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_planes, os):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.xception_features = Xception(in_planes, os)\n",
    "\n",
    "        if os == 16:\n",
    "            rates = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            rates = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # ASPP\n",
    "        self.aspp1 = ASPP(2048, 256, rate=rates[0])\n",
    "        self.aspp2 = ASPP(2048, 256, rate=rates[1])\n",
    "        self.aspp3 = ASPP(2048, 256, rate=rates[2])\n",
    "        self.aspp4 = ASPP(2048, 256, rate=rates[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             nn.Conv2d(2048, 256, 1, stride=1, bias=False),\n",
    "                                             nn.BatchNorm2d(256),\n",
    "                                             nn.ReLU())\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        x, low_level_features = self.xception_features(x)\n",
    "\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x, low_level_features\n",
    "    \n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_planes, n_classes, recon=False):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(128, 48, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if recon:\n",
    "            self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                        nn.BatchNorm2d(256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                        nn.BatchNorm2d(256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(256, in_planes, kernel_size=1, stride=1))\n",
    "        else:\n",
    "            self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                        nn.BatchNorm2d(256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                        nn.BatchNorm2d(256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(256, n_classes, kernel_size=1, stride=1))\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x, low_level_features):\n",
    "\n",
    "        x = F.upsample(x, size=(int(math.ceil(512/4)),\n",
    "                                int(math.ceil(512/4))),\n",
    "                                mode='bilinear', align_corners=True) # x upsample\n",
    "        \n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.upsample(x, size=(512, 512), mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "class DeepLabv3plus(nn.Module):\n",
    "    def __init__(self, n_classes, in_planes=3, recon=False, os=16):\n",
    "        super(DeepLabv3plus, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(in_planes, os)\n",
    "        self.decoder = Decoder(in_planes, n_classes, recon=recon)\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, low_level_features = self.encoder(x)\n",
    "        x = self.decoder(x, low_level_features)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsupervised\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, target_dir, transform=None, recon=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.recon = recon\n",
    "        # self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.target_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_list = sorted(os.listdir(self.img_dir))\n",
    "        image = cv2.imread(os.path.join(self.img_dir, img_list[idx]))\n",
    "        image = self.preprocessing(image)\n",
    "        image = image / 255\n",
    "\n",
    "        target_list = sorted(os.listdir(self.target_dir))\n",
    "        if self.recon:\n",
    "            target = cv2.imread(os.path.join(self.target_dir, target_list[idx]))\n",
    "            target = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)\n",
    "            target = cv2.resize(target, (512, 512))\n",
    "            target = target / 255\n",
    "        elif not self.recon:\n",
    "            target = cv2.imread(os.path.join(self.target_dir, target_list[idx]), cv2.IMREAD_BGR2RGB)\n",
    "        # target = cv2.resize(target, (512, 512))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            target = self.transform(target)\n",
    "            \n",
    "        return image, target\n",
    "\n",
    "    def preprocessing(self, image):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        image[:, :, 0] = clahe.apply(image[:, :, 0])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_LAB2RGB)\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsupervised\n",
    "train_dataset = CustomImageDataset(\n",
    "    img_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/EyePACS',\n",
    "    target_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/EyePACS',\n",
    "    transform=ToTensor(),\n",
    "    recon=True\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = True\n",
    "model = DeepLabv3plus(in_planes=3, n_classes=None, os=16, recon=recon)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "print('Start training..')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, target in tqdm(train_dataloader):\n",
    "        images = images.to(device).float()\n",
    "        target = target.to(device).float()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSMD Deeplabv3plus (seg & reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_planes, os):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.xception_features = Xception(in_planes, os)\n",
    "\n",
    "        if os == 16:\n",
    "            rates = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            rates = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # ASPP\n",
    "        self.aspp1 = ASPP(2048, 256, rate=rates[0])\n",
    "        self.aspp2 = ASPP(2048, 256, rate=rates[1])\n",
    "        self.aspp3 = ASPP(2048, 256, rate=rates[2])\n",
    "        self.aspp4 = ASPP(2048, 256, rate=rates[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             nn.Conv2d(2048, 256, 1, stride=1, bias=False),\n",
    "                                             nn.BatchNorm2d(256),\n",
    "                                             nn.ReLU())\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, low_level_features = self.xception_features(x)\n",
    "\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x, low_level_features\n",
    "    \n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_planes, n_classes, recon=False):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(128, 48, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if recon:\n",
    "            self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                           nn.BatchNorm2d(256),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                           nn.BatchNorm2d(256),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Conv2d(256, in_planes, kernel_size=1, stride=1))\n",
    "        else:\n",
    "            self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                             nn.BatchNorm2d(256),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                             nn.BatchNorm2d(256),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Conv2d(256, n_classes, kernel_size=1, stride=1))\n",
    "\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x, low_level_features):\n",
    "        x = F.upsample(x, size=(int(math.ceil(512/4)),\n",
    "                                int(math.ceil(512/4))),\n",
    "                                mode='bilinear', align_corners=True) # x upsample\n",
    "        \n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.upsample(x, size=(512, 512), mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "class SSMDDeepLabv3plus(nn.Module):\n",
    "    def __init__(self, n_classes, in_planes=3, os=16):\n",
    "        super(DeepLabv3plus, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(in_planes, os)\n",
    "        self.reconstruction = Decoder(in_planes, n_classes=None, recon=True)\n",
    "\n",
    "        self.microaneurysms = Decoder(in_planes, n_classes, recon=False)\n",
    "        self.hemohedges = Decoder(in_planes, n_classes, recon=False)\n",
    "        self.hardexudates = Decoder(in_planes, n_classes, recon=False)\n",
    "        self.softexudates = Decoder(in_planes, n_classes, recon=False)\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, low_level_features = self.encoder(x)\n",
    "        \n",
    "        x1 = self.microaneurysms(x, low_level_features)\n",
    "        x2 = self.hemohedges(x, low_level_features)\n",
    "        x3 = self.hardexudates(x, low_level_features)\n",
    "        x4 = self.softexudates(x, low_level_features)\n",
    "        return x, x1, x2, x3, x4\n",
    "        \n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, recon_dir, micro_dir, hemo_dir, hard_dir, soft_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.recon_dir = recon_dir\n",
    "        self.micro_dir = micro_dir\n",
    "        self.hemo_dir = hemo_dir\n",
    "        self.hard_dir = hard_dir\n",
    "        self.soft_dir = soft_dir\n",
    "        self.transform = transform\n",
    "        # self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.img_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_list = sorted(os.listdir(self.img_dir))\n",
    "        image = cv2.imread(os.path.join(self.img_dir, img_list[idx]))\n",
    "        image = self.preprocessing(image)\n",
    "        image = image / 255\n",
    "\n",
    "        recon_list = sorted(os.listdir(self.recon_dir))\n",
    "        recon = cv2.imread(os.path.join(self.recon_dir, recon_list[idx]), cv2.IMREAD_BGR2RGB)\n",
    "        # recon = cv2.resize(recon, (512, 512))\n",
    "        recon = recon / 255\n",
    "\n",
    "        micro_list = sorted(os.listdir(self.micro_dir))\n",
    "        micro = cv2.imread(os.path.join(self.micro_dir, micro_list[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        # micro = cv2.resize(micro, (512, 512))\n",
    "\n",
    "        hemo_list = sorted(os.listdir(self.hemo_dir))\n",
    "        hemo = cv2.imread(os.path.join(self.hemo_dir, hemo_list[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        # hemo = cv2.resize(hemo, (512, 512))\n",
    "\n",
    "        hard_list = sorted(os.listdir(self.hard_dir))\n",
    "        hard = cv2.imread(os.path.join(self.hard_dir, hard_list[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        # hard = cv2.resize(hard, (512, 512))\n",
    "\n",
    "        soft_list = sorted(os.listdir(self.soft_dir))\n",
    "        soft = cv2.imread(os.path.join(self.soft_dir, soft_list[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        # soft = cv2.resize(soft, (512, 512))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            recon = self.transform(recon)\n",
    "            micro = self.transform(micro)\n",
    "            hemo = self.transform(hemo)\n",
    "            hard = self.transform(hard)\n",
    "            soft = self.transform(soft)\n",
    "        return image, recon, micro, hemo, hard, soft\n",
    "\n",
    "    def preprocessing(self, image):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        image[:, :, 0] = clahe.apply(image[:, :, 0])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_LAB2RGB)\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised\n",
    "transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CustomImageDataset(\n",
    "    img_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/train/Original_Images',\n",
    "    recon_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/train/Original_Images',\n",
    "    micro_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/train/1.Microaneurysms',\n",
    "    hemo_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/train/2.Hemohedges',\n",
    "    hard_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/train/3.HardExudates',\n",
    "    soft_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/train/4.SoftExudates',\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "val_dataset = CustomImageDataset(\n",
    "    img_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/val/Original_Images',\n",
    "    recon_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/val/Original_Images',\n",
    "    micro_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/val/1.Microaneurysms',\n",
    "    hemo_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/val/2.Hemohedges',\n",
    "    hard_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/val/3.HardExudates',\n",
    "    soft_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/val/4.SoftExudates',\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "test_dataset = CustomImageDataset(\n",
    "    img_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/test/Original_Images',\n",
    "    recon_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/test/Original_Images',\n",
    "    micro_dir='/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/test/1.Microaneurysms',\n",
    "    hemo_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/test/2.Hemohedges',\n",
    "    hard_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/test/3.HardExudates',\n",
    "    soft_dir = '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/FGADR/test/4.SoftExudates',\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised, micro\n",
    "model = SSMDDeepLabv3plus(in_planes=3, n_classes=2, os=16)\n",
    "model.encoder.load_state_dict(torch.load('/content/drive/MyDrive/Projects/dr_segmentation_pytorch/models/encoder.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 150\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "alpha = 0.2\n",
    "beta = 0.8\n",
    "print('Start training..')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, recon, micro, hemo, hard, soft in tqdm(train_dataloader):\n",
    "        images = images.to(device).float()\n",
    "        recon = recon.to(device).float()\n",
    "        micro = micro.to(device).long()\n",
    "        hemo = hemo.to(device).long()\n",
    "        hard = hard.to(device).long()\n",
    "        soft = soft.to(device).long()\n",
    "        x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "        x_loss = criterion(outputs, recon)\n",
    "        x1_loss = criterion(x1, micro)\n",
    "        x2_loss = criterion(x2, hemo)\n",
    "        x3_loss = criterion(x3, hard)\n",
    "        x4_loss = criterion(x4, soft)\n",
    "\n",
    "        seg_loss = beta * x1_loss + (1-beta) * (x2_loss + x3_loss + x4_loss)\n",
    "        ssmd_loss = alpha * x_loss + seg_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        ssmd_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += ssmd_loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, recon, micro, hemo, hard, soft in tqdm(val_dataloader):\n",
    "            images = images.to(device).float()\n",
    "            recon = recon.to(device).float()\n",
    "            micro = micro.to(device).long()\n",
    "            hemo = hemo.to(device).long()\n",
    "            hard = hard.to(device).long()\n",
    "            soft = soft.to(device).long()\n",
    "            x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "            x_loss = criterion(outputs, recon)\n",
    "            x1_loss = criterion(x1, micro)\n",
    "            x2_loss = criterion(x2, hemo)\n",
    "            x3_loss = criterion(x3, hard)\n",
    "            x4_loss = criterion(x4, soft)\n",
    "\n",
    "            seg_loss = beta * x1_loss + (1-beta) * (x2_loss + x3_loss + x4_loss)\n",
    "            ssmd_loss = alpha * x_loss + seg_loss\n",
    "            val_loss += ssmd_loss.item()\n",
    "\n",
    "    early_stopping = EarlyStopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/models/ssmd_deeplabv3plus_micro.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised, hemo\n",
    "model = SSMDDeepLabv3plus(in_planes=3, n_classes=2, os=16)\n",
    "model.encoder.load_state_dict(torch.load('/content/drive/MyDrive/Projects/dr_segmentation_pytorch/models/encoder.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 150\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "alpha = 0.2\n",
    "beta = 0.8\n",
    "print('Start training..')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, recon, micro, hemo, hard, soft in tqdm(train_dataloader):\n",
    "        images = images.to(device).float()\n",
    "        recon = recon.to(device).float()\n",
    "        micro = micro.to(device).long()\n",
    "        hemo = hemo.to(device).long()\n",
    "        hard = hard.to(device).long()\n",
    "        soft = soft.to(device).long()\n",
    "        x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "        x_loss = criterion(outputs, recon)\n",
    "        x1_loss = criterion(x1, micro)\n",
    "        x2_loss = criterion(x2, hemo)\n",
    "        x3_loss = criterion(x3, hard)\n",
    "        x4_loss = criterion(x4, soft)\n",
    "\n",
    "        seg_loss = beta * x2_loss + (1-beta) * (x1_loss + x3_loss + x4_loss)\n",
    "        ssmd_loss = alpha * x_loss + seg_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        ssmd_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += ssmd_loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, recon, micro, hemo, hard, soft in tqdm(val_dataloader):\n",
    "            images = images.to(device).float()\n",
    "            recon = recon.to(device).float()\n",
    "            micro = micro.to(device).long()\n",
    "            hemo = hemo.to(device).long()\n",
    "            hard = hard.to(device).long()\n",
    "            soft = soft.to(device).long()\n",
    "            x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "            x_loss = criterion(outputs, recon)\n",
    "            x1_loss = criterion(x1, micro)\n",
    "            x2_loss = criterion(x2, hemo)\n",
    "            x3_loss = criterion(x3, hard)\n",
    "            x4_loss = criterion(x4, soft)\n",
    "\n",
    "            seg_loss = beta * x2_loss + (1-beta) * (x1_loss + x3_loss + x4_loss)\n",
    "            ssmd_loss = alpha * x_loss + seg_loss\n",
    "            val_loss += ssmd_loss.item()\n",
    "\n",
    "    early_stopping = EarlyStopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/models/ssmd_deeplabv3plus_hemo.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised, hard\n",
    "model = SSMDDeepLabv3plus(in_planes=3, n_classes=2, os=16)\n",
    "model.encoder.load_state_dict(torch.load('/content/drive/MyDrive/Projects/dr_segmentation_pytorch/models/encoder.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 150\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "alpha = 0.2\n",
    "beta = 0.8\n",
    "print('Start training..')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, recon, micro, hemo, hard, soft in tqdm(train_dataloader):\n",
    "        images = images.to(device).float()\n",
    "        recon = recon.to(device).float()\n",
    "        micro = micro.to(device).long()\n",
    "        hemo = hemo.to(device).long()\n",
    "        hard = hard.to(device).long()\n",
    "        soft = soft.to(device).long()\n",
    "        x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "        x_loss = criterion(outputs, recon)\n",
    "        x1_loss = criterion(x1, micro)\n",
    "        x2_loss = criterion(x2, hemo)\n",
    "        x3_loss = criterion(x3, hard)\n",
    "        x4_loss = criterion(x4, soft)\n",
    "\n",
    "        seg_loss = beta * x3_loss + (1-beta) * (x1_loss + x2_loss + x4_loss)\n",
    "        ssmd_loss = alpha * x_loss + seg_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        ssmd_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += ssmd_loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, recon, micro, hemo, hard, soft in tqdm(val_dataloader):\n",
    "            images = images.to(device).float()\n",
    "            recon = recon.to(device).float()\n",
    "            micro = micro.to(device).long()\n",
    "            hemo = hemo.to(device).long()\n",
    "            hard = hard.to(device).long()\n",
    "            soft = soft.to(device).long()\n",
    "            x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "            x_loss = criterion(outputs, recon)\n",
    "            x1_loss = criterion(x1, micro)\n",
    "            x2_loss = criterion(x2, hemo)\n",
    "            x3_loss = criterion(x3, hard)\n",
    "            x4_loss = criterion(x4, soft)\n",
    "\n",
    "            seg_loss = beta * x3_loss + (1-beta) * (x1_loss + x2_loss + x4_loss)\n",
    "            ssmd_loss = alpha * x_loss + seg_loss\n",
    "            val_loss += ssmd_loss.item()\n",
    "\n",
    "    early_stopping = EarlyStopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/models/ssmd_deeplabv3plus_hard.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised, soft\n",
    "model = SSMDDeepLabv3plus(in_planes=3, n_classes=2, os=16)\n",
    "model.encoder.load_state_dict(torch.load('/content/drive/MyDrive/Projects/dr_segmentation_pytorch/models/encoder.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 150\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "alpha = 0.2\n",
    "beta = 0.8\n",
    "print('Start training..')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, recon, micro, hemo, hard, soft in tqdm(train_dataloader):\n",
    "        images = images.to(device).float()\n",
    "        recon = recon.to(device).float()\n",
    "        micro = micro.to(device).long()\n",
    "        hemo = hemo.to(device).long()\n",
    "        hard = hard.to(device).long()\n",
    "        soft = soft.to(device).long()\n",
    "        x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "        x_loss = criterion(outputs, recon)\n",
    "        x1_loss = criterion(x1, micro)\n",
    "        x2_loss = criterion(x2, hemo)\n",
    "        x3_loss = criterion(x3, hard)\n",
    "        x4_loss = criterion(x4, soft)\n",
    "\n",
    "        seg_loss = beta * x4_loss + (1-beta) * (x1_loss + x2_loss + x3_loss)\n",
    "        ssmd_loss = alpha * x_loss + seg_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        ssmd_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += ssmd_loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, recon, micro, hemo, hard, soft in tqdm(val_dataloader):\n",
    "            images = images.to(device).float()\n",
    "            recon = recon.to(device).float()\n",
    "            micro = micro.to(device).long()\n",
    "            hemo = hemo.to(device).long()\n",
    "            hard = hard.to(device).long()\n",
    "            soft = soft.to(device).long()\n",
    "            x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "            x_loss = criterion(outputs, recon)\n",
    "            x1_loss = criterion(x1, micro)\n",
    "            x2_loss = criterion(x2, hemo)\n",
    "            x3_loss = criterion(x3, hard)\n",
    "            x4_loss = criterion(x4, soft)\n",
    "\n",
    "            seg_loss = beta * x4_loss + (1-beta) * (x1_loss + x2_loss + x3_loss)\n",
    "            ssmd_loss = alpha * x_loss + seg_loss\n",
    "            val_loss += ssmd_loss.item()\n",
    "\n",
    "    early_stopping = EarlyStopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/drive/MyDrive/Projects/dr_segmentation_pytorch/models/ssmd_deeplabv3plus_soft.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(pred, target):\n",
    "    smooth = 1e-6\n",
    "    intersection = (pred * target).sum()\n",
    "    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "micro_score = 0.0\n",
    "hemo_score = 0.0\n",
    "hard_score = 0.0\n",
    "soft_score = 0.0\n",
    "with torch.no_grad():\n",
    "    for image, recon, micro, hemo, hard, soft in tqdm(test_dataloader):\n",
    "        images = images.to(device).float()\n",
    "        micro = micro.to(device).long()\n",
    "        hemo = hemo.to(device).long()\n",
    "        hard = hard.to(device).long()\n",
    "        soft = soft.to(device).long()\n",
    "        x, x1, x2, x3, x4 = model(images)\n",
    "\n",
    "        x1_loss = dice_score(x1, micro)\n",
    "        x2_loss = dice_score(x2, hemo)\n",
    "        x3_loss = dice_score(x3, hard)\n",
    "        x4_loss = dice_score(x4, soft)\n",
    "\n",
    "        # 각 병변의 dice score 평균\n",
    "        micro_score += x1_loss\n",
    "        hemo_score += x2_loss\n",
    "        hard_score += x3_loss\n",
    "        soft_score += x4_loss\n",
    "\n",
    "    print(f'Test Loss: {test_loss/len(test_dataloader)}')\n",
    "    print(f'Microaneurysms Dice Score: {micro_score/len(test_dataloader)}')\n",
    "    print(f'Hemohedges Dice Score: {hemo_score/len(test_dataloader)}')\n",
    "    print(f'HardExudates Dice Score: {hard_score/len(test_dataloader)}')\n",
    "    print(f'SoftExudates Dice Score: {soft_score/len(test_dataloader)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
