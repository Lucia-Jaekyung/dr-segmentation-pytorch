{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "from xception import Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, rate):\n",
    "        super(ASPP, self).__init__()\n",
    "        if rate == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = rate\n",
    "        \n",
    "        self.atrous_convolution == nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=1, padding=padding, dilation=rate, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.__init_weight()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabv3plus(nn.Module):\n",
    "    def __init__(self, n_input_channels=3, n_classes=4, os=16, _print=True):\n",
    "        if _print:\n",
    "            print(\"Constructing DeepLabv3+ model...\")\n",
    "            print(f\"Number of input channels: {n_input_channels}\")\n",
    "            print(f\"Output stride: {os}\")\n",
    "            print(f\"Number of classes: {n_classes}\")\n",
    "        super(DeepLabv3plus, self).__init__()\n",
    "\n",
    "        # Atrous Convolution\n",
    "        self.xception_features = Xception(n_input_channels, os)\n",
    "        # ASPP\n",
    "        if os == 16:\n",
    "            rates = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            rates = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.aspp1 = ASPP(2048, 256, rate=rates[0])\n",
    "        self.aspp2 = ASPP(2048, 256, rate=rates[1])\n",
    "        self.aspp3 = ASPP(2048, 256, rate=rates[2])\n",
    "        self.aspp4 = ASPP(2048, 256, rate=rates[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             nn.Conv2d(2048, 256, 1, stride=1, bias=False),\n",
    "                                             nn.BatchNorm2d(256),\n",
    "                                             nn.ReLU())\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # adopt [1x1, 48] for channel reduction\n",
    "        self.conv2 = nn.Conv2d(256, 48, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(304, 256, 3, stride=1, padding=1, bias=False),\n",
    "                                       nn.BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, 256, 3, stride=1, padding=1, bias=False),\n",
    "                                       nn.BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                        nn.Conv2d(256, n_classes, 1, stride=1))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x, low_level_features = self.xception_features(input)\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.concat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.upsample(x, size=(int(math.ceil(input.size()[-2]/4)),\n",
    "                                int(math.ceil(input.size()[-1]/4))),\n",
    "                                mode='bilinear', align_corners=True)\n",
    "        \n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "        x = torch.concat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.upsample(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = DeepLabv3plus(n_input_channe=3, n_classes=4, os=16, _print=True)\n",
    "    model.eval()\n",
    "    image = torch.randn(1, 3, 512, 512)\n",
    "    with torch.no_grad():\n",
    "        output = model.forward(image)\n",
    "    print(output.size())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
